{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03: Spatial Interpolation - Basic Techniques\n",
    "\n",
    "**Goal:** To predict values at unsampled locations using data from a limited number of sample points. This is a foundational task for creating continuous surfaces, essential for environmental monitoring, resource management, and more.\n",
    "\n",
    "In this notebook, we'll explore two common methods:\n",
    "1.  **Inverse Distance Weighting (IDW):** A straightforward deterministic method where the influence of a sample point is inversely proportional to its distance from the prediction location.\n",
    "2.  **Machine Learning Approach:** Using a standard regression model (`RandomForestRegressor`) where the spatial coordinates (X and Y) are the primary features to predict the value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setup and Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.interpolate import Rbf\n",
    "import contextily as cx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate Synthetic Data\n",
    "\n",
    "To test our interpolation methods, we need data where we know the \"ground truth.\" We'll create a synthetic landscape where a value (e.g., temperature) is determined by a mathematical function. Then, we'll take a small number of random samples from this landscape, simulating real-world sensor readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the boundary for our study area\n",
    "x_min, x_max = 0, 100\n",
    "y_min, y_max = 0, 100\n",
    "\n",
    "# Ground Truth Function: A combination of peaks\n",
    "def ground_truth_func(x, y):\n",
    "    return (100 * np.exp(-((x - 25)**2 + (y - 75)**2) / 200) + \n",
    "            75 * np.exp(-((x - 70)**2 + (y - 30)**2) / 300) + \n",
    "            50 * np.sin(x/10) + 50 * np.cos(y/10))\n",
    "\n",
    "# Create a dense grid for visualizing the ground truth\n",
    "grid_x, grid_y = np.meshgrid(np.linspace(x_min, x_max, 200), np.linspace(y_min, y_max, 200))\n",
    "grid_z_truth = ground_truth_func(grid_x, grid_y)\n",
    "\n",
    "# Generate random sample points (our 'sensors')\n",
    "num_samples = 50\n",
    "np.random.seed(42)\n",
    "sample_x = np.random.uniform(x_min, x_max, num_samples)\n",
    "sample_y = np.random.uniform(y_min, y_max, num_samples)\n",
    "sample_z = ground_truth_func(sample_x, sample_y) + np.random.normal(0, 5, num_samples) # Add some noise\n",
    "\n",
    "# Create a GeoDataFrame for the sample points\n",
    "samples_gdf = gpd.GeoDataFrame(\n",
    "    {'value': sample_z},\n",
    "    geometry=[Point(x, y) for x, y in zip(sample_x, sample_y)],\n",
    "    crs=\"EPSG:32630\" # Using a projected CRS like UTM Zone 30N for distance calcs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualize the Ground Truth and Sample Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "im = ax.imshow(grid_z_truth, extent=[x_min, x_max, y_min, y_max], origin='lower', cmap='viridis')\n",
    "samples_gdf.plot(ax=ax, marker='o', color='red', markersize=50, edgecolor='white', label='Sample Points')\n",
    "ax.set_title('Ground Truth and Sample Locations')\n",
    "ax.set_xlabel('X-Coordinate')\n",
    "ax.set_ylabel('Y-Coordinate')\n",
    "ax.legend()\n",
    "fig.colorbar(im, ax=ax, label='Value')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Interpolation Method 1: Inverse Distance Weighting (IDW)\n",
    "\n",
    "IDW assumes that points closer to the prediction location are more similar and should have more weight. The weight is typically `1/d^p`, where `d` is the distance and `p` is a power parameter (usually 2).\n",
    "\n",
    "We will use `scipy.interpolate.Rbf` (Radial Basis Function) to perform a similar type of interpolation, which is flexible and effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RBF interpolator function\n",
    "# The 'function' argument determines the type of radial basis function.\n",
    "# 'inverse_multiquadric' is a common choice for smooth interpolation.\n",
    "rbfi = Rbf(sample_x, sample_y, sample_z, function='inverse_multiquadric')\n",
    "\n",
    "# Apply the interpolator to our dense grid\n",
    "grid_z_idw = rbfi(grid_x, grid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Interpolation Method 2: Machine Learning (Random Forest)\n",
    "\n",
    "Here, we treat interpolation as a standard regression problem. The features (`X`) are the coordinates of our sample points, and the target (`y`) is the value at those points. We train a model and then ask it to predict the values for every point on our dense grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the training data\n",
    "X_train = np.vstack([sample_x, sample_y]).T\n",
    "y_train = sample_z\n",
    "\n",
    "# Prepare the prediction data (the entire grid)\n",
    "X_predict = np.vstack([grid_x.ravel(), grid_y.ravel()]).T\n",
    "\n",
    "# Initialize and train the Random Forest model\n",
    "rf = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the grid\n",
    "grid_z_rf = rf.predict(X_predict)\n",
    "grid_z_rf = grid_z_rf.reshape(grid_x.shape) # Reshape back to grid format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Compare the Results\n",
    "\n",
    "Now we can visually compare our two interpolated surfaces against the ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(24, 7), sharey=True)\n",
    "\n",
    "# Plot Ground Truth\n",
    "im0 = axes[0].imshow(grid_z_truth, extent=[x_min, x_max, y_min, y_max], origin='lower', cmap='viridis')\n",
    "axes[0].scatter(sample_x, sample_y, c='red', edgecolor='white', s=20)\n",
    "axes[0].set_title('A) Ground Truth')\n",
    "axes[0].set_xlabel('X-Coordinate')\n",
    "axes[0].set_ylabel('Y-Coordinate')\n",
    "fig.colorbar(im0, ax=axes[0], orientation='horizontal', pad=0.1, label='Value')\n",
    "\n",
    "# Plot IDW (RBF) Interpolation\n",
    "im1 = axes[1].imshow(grid_z_idw, extent=[x_min, x_max, y_min, y_max], origin='lower', cmap='viridis')\n",
    "axes[1].scatter(sample_x, sample_y, c='red', edgecolor='white', s=20)\n",
    "axes[1].set_title('B) IDW (RBF) Interpolation')\n",
    "axes[1].set_xlabel('X-Coordinate')\n",
    "fig.colorbar(im1, ax=axes[1], orientation='horizontal', pad=0.1, label='Value')\n",
    "\n",
    "# Plot Random Forest Interpolation\n",
    "im2 = axes[2].imshow(grid_z_rf, extent=[x_min, x_max, y_min, y_max], origin='lower', cmap='viridis')\n",
    "axes[2].scatter(sample_x, sample_y, c='red', edgecolor='white', s=20)\n",
    "axes[2].set_title('C) Random Forest Interpolation')\n",
    "axes[2].set_xlabel('X-Coordinate')\n",
    "fig.colorbar(im2, ax=ax_s[2], orientation='horizontal', pad=0.1, label='Value')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Discussion:\n",
    "# - The RBF/IDW method (B) creates a very smooth, visually pleasing surface that honors the sample points exactly. It's a classic interpolation result.\n",
    "# - The Random Forest method (C) produces a more patchy result. This is characteristic of tree-based models. It doesn't extrapolate beyond the range of the training data well but can capture complex, non-linear relationships if enough data is provided.\n",
    "# - Neither method perfectly recreates the ground truth, which is expected given the sparse and noisy sample data. The best method often depends on the nature of the data and the specific goals of the analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
